import OpenAI from 'openai';
import { searchVectorStore, getStoredDocuments, getTotalChunksCount } from './document-processor';

type ModelType = 'deepseek' | 'kimi';

interface ChatMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
}

interface ChatResult {
  response: string;
  sources: string[];
  model: string;
}

const modelConfigs: Record<ModelType, {
  apiKey: string | undefined;
  baseURL: string;
  model: string;
  displayName: string;
}> = {
  deepseek: {
    apiKey: process.env.DEEPSEEK_API_KEY,
    baseURL: 'https://api.deepseek.com/v1',
    model: 'deepseek-chat',
    displayName: 'DeepSeek',
  },
  kimi: {
    apiKey: process.env.KIMI_API_KEY,
    baseURL: 'https://api.moonshot.cn/v1',
    model: 'moonshot-v1-8k',
    displayName: 'Kimi',
  },
};

function getClient(modelType: ModelType): OpenAI {
  const config = modelConfigs[modelType];
  if (!config.apiKey) {
    throw new Error(`API key for ${modelType} is not configured`);
  }
  return new OpenAI({
    apiKey: config.apiKey,
    baseURL: config.baseURL,
  });
}

/**
 * Build system prompt - Strict 100% original text mode
 */
function buildSystemPrompt(documents: string[], context: string, hasContext: boolean): string {
  if (!hasContext) {
    return `ä½ æ˜¯çŸ¥è¯†åº“æŸ¥è¯¢åŠ©æ‰‹ã€‚å›å¤ï¼šçŸ¥è¯†åº“æœªåŒ…å«æ­¤ç­”æ¡ˆã€‚`;
  }

  return `ä½ æ˜¯çŸ¥è¯†åº“æŸ¥è¯¢åŠ©æ‰‹ã€‚ä¸¥æ ¼æŒ‰ä»¥ä¸‹è§„åˆ™å›ç­”ï¼š

## çŸ¥è¯†åº“åŸæ–‡ï¼ˆå”¯ä¸€ä¿¡æ¯æ¥æºï¼‰

${context}

---

## å›ç­”è§„åˆ™ï¼ˆå¿…é¡»100%éµå®ˆï¼‰

**è§„åˆ™1ï¼šå®Œå…¨åŒ¹é…æ—¶ï¼ˆä¼˜å…ˆï¼‰**
è‹¥çŸ¥è¯†åº“ä¸­æœ‰ä¸é—®é¢˜ç›´æ¥ç›¸å…³çš„å†…å®¹ï¼Œå¿…é¡»100%åŸæ–‡å¼•ç”¨ï¼Œä¸€å­—ä¸æ”¹ï¼š

### ğŸ“– åŸæ–‡å¼•ç”¨
> [å®Œæ•´å¤åˆ¶åŸæ–‡ï¼Œä¸å¾—æ”¹åŠ¨ä»»ä½•å­—è¯]

**å¼•ç”¨è‡ªã€Šæ–‡æ¡£åã€‹**

**è§„åˆ™2ï¼šæ— å®Œå…¨åŒ¹é…ä½†æœ‰ç›¸å…³å†…å®¹æ—¶**
ç»“åˆçŸ¥è¯†åº“ä¸­æœ€ç›¸å…³çš„æ®µè½ç”Ÿæˆç­”æ¡ˆï¼Œå¹¶æ ‡æ³¨æ¥æºï¼š

### ğŸ“– ç›¸å…³å†…å®¹
> [å¤åˆ¶æœ€ç›¸å…³çš„åŸæ–‡æ®µè½]

**å¼•ç”¨è‡ªã€Šæ–‡æ¡£åã€‹**

### ğŸ’¡ ç»¼åˆåˆ†æ
[åŸºäºä¸Šè¿°åŸæ–‡å†…å®¹è¿›è¡Œåˆ†æï¼Œæ˜ç¡®è¯´æ˜ä¾æ®]

**è§„åˆ™3ï¼šå®Œå…¨æ— ç›¸å…³å†…å®¹æ—¶**
ç›´æ¥å›å¤ï¼š**çŸ¥è¯†åº“æœªåŒ…å«æ­¤ç­”æ¡ˆ**

---

## ç»å¯¹ç¦æ­¢
- âŒ ç¦æ­¢æ”¹å†™ã€è½¬è¿°ã€æ¦‚æ‹¬åŸæ–‡
- âŒ ç¦æ­¢æ·»åŠ çŸ¥è¯†åº“ä¸­ä¸å­˜åœ¨çš„ä¿¡æ¯
- âŒ ç¦æ­¢ç¼–é€ å†…å®¹
- âŒ ç¦æ­¢ä½¿ç”¨è‡ªå·±çš„çŸ¥è¯†å›ç­”

## è¾“å‡ºæ ¼å¼
æ¯æ¬¡å›ç­”å¿…é¡»åŒ…å«ï¼š
1. ğŸ“– åŸæ–‡å¼•ç”¨ï¼ˆ100%åŸæ–‡å¤åˆ¶ï¼‰
2. å¼•ç”¨æ¥æºæ ‡æ³¨ï¼ˆå¼•ç”¨è‡ªã€Šæ–‡æ¡£åã€‹ï¼‰
3. å¦‚æœ‰å¤šæ®µç›¸å…³å†…å®¹ï¼Œå…¨éƒ¨åˆ—å‡º`;
}

export async function chat(
  message: string,
  modelType: ModelType = 'deepseek',
  history: ChatMessage[] = []
): Promise<ChatResult> {
  if (!['deepseek', 'kimi'].includes(modelType)) {
    modelType = 'deepseek';
  }

  const documents = getStoredDocuments();
  const totalChunks = getTotalChunksCount();

  console.log(`[Chat] Query: "${message}"`);
  console.log(`[Chat] Documents: ${documents.join(', ') || 'none'}, Total chunks: ${totalChunks}`);

  const relevantChunks = await searchVectorStore(message, 10);
  console.log(`[Chat] Retrieved ${relevantChunks.length} chunks`);

  let context = '';
  const sources: string[] = [];

  if (relevantChunks.length > 0) {
    context = relevantChunks
      .map((chunk, index) => {
        const docName = chunk.metadata.fileName;
        if (!sources.includes(docName)) {
          sources.push(docName);
        }
        return `ã€ç¬¬${index + 1}æ®µã€‘æ¥æºï¼šã€Š${docName}ã€‹
"${chunk.text}"`;
      })
      .join('\n\n---\n\n');
  }

  const hasContext = context.length > 0;
  const systemPrompt = buildSystemPrompt(documents, context, hasContext);

  const messages: ChatMessage[] = [
    { role: 'system', content: systemPrompt },
    ...history.slice(-4),
    { role: 'user', content: message },
  ];

  const modelOrder: ModelType[] = modelType === 'kimi' ? ['kimi', 'deepseek'] : ['deepseek', 'kimi'];
  let lastError: Error | null = null;

  for (const model of modelOrder) {
    try {
      const config = modelConfigs[model];
      if (!config.apiKey) continue;

      console.log(`[Chat] Using: ${config.displayName}`);
      const client = getClient(model);

      const completion = await client.chat.completions.create({
        model: config.model,
        messages: messages.map(m => ({ role: m.role, content: m.content })),
        temperature: 0, // Zero temperature for 100% deterministic strict adherence
        max_tokens: 4000,
      });

      const response = completion.choices[0]?.message?.content || 'æ— æ³•ç”Ÿæˆå›å¤';
      console.log(`[Chat] Response from ${config.displayName}`);

      return { response, sources, model: config.displayName };
    } catch (error) {
      lastError = error as Error;
      console.error(`[Chat] Error from ${model}:`, error);
    }
  }

  throw lastError || new Error('AIæœåŠ¡å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥');
}

export function getAvailableModels(): { id: ModelType; name: string; available: boolean }[] {
  return Object.entries(modelConfigs).map(([id, config]) => ({
    id: id as ModelType,
    name: config.displayName,
    available: !!config.apiKey,
  }));
}
