import OpenAI from 'openai';
import { searchVectorStore, getStoredDocuments, getTotalChunksCount } from './document-processor';

type ModelType = 'deepseek' | 'kimi';

interface ChatMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
}

interface ChatResult {
  response: string;
  sources: string[];
  model: string;
}

const modelConfigs: Record<ModelType, {
  apiKey: string | undefined;
  baseURL: string;
  model: string;
  displayName: string;
}> = {
  deepseek: {
    apiKey: process.env.DEEPSEEK_API_KEY,
    baseURL: 'https://api.deepseek.com/v1',
    model: 'deepseek-chat',
    displayName: 'DeepSeek',
  },
  kimi: {
    apiKey: process.env.KIMI_API_KEY,
    baseURL: 'https://api.moonshot.cn/v1',
    model: 'moonshot-v1-8k',
    displayName: 'Kimi',
  },
};

function getClient(modelType: ModelType): OpenAI {
  const config = modelConfigs[modelType];
  if (!config.apiKey) {
    throw new Error(`API key for ${modelType} is not configured`);
  }
  return new OpenAI({
    apiKey: config.apiKey,
    baseURL: config.baseURL,
  });
}

/**
 * Build system prompt - Strict original text mode
 */
function buildSystemPrompt(documents: string[], context: string, hasContext: boolean): string {
  if (!hasContext) {
    return `ä½ æ˜¯çŸ¥è¯†åº“æŸ¥è¯¢åŠ©æ‰‹ã€‚å½“å‰æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œè¯·ç”¨æˆ·è°ƒæ•´é—®é¢˜æˆ–ä¸Šä¼ ç›¸å…³æ–‡æ¡£ã€‚`;
  }

  return `ä½ æ˜¯çŸ¥è¯†åº“æŸ¥è¯¢åŠ©æ‰‹ã€‚ä½ çš„å”¯ä¸€ä»»åŠ¡æ˜¯ä»çŸ¥è¯†åº“ä¸­æå–å¹¶å±•ç¤ºåŸæ–‡å†…å®¹ã€‚

## çŸ¥è¯†åº“åŸæ–‡

${context}

---

## è¾“å‡ºè¦æ±‚ï¼ˆä¸¥æ ¼éµå®ˆï¼‰

æ ¹æ®ç”¨æˆ·é—®é¢˜ï¼Œä»ä¸Šæ–¹çŸ¥è¯†åº“åŸæ–‡ä¸­æ‰¾å‡ºç›¸å…³å†…å®¹ï¼ŒæŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

### ğŸ“– ç›¸å…³åŸæ–‡

ç›´æ¥å¤åˆ¶ç²˜è´´çŸ¥è¯†åº“ä¸­ä¸é—®é¢˜ç›¸å…³çš„æ®µè½ï¼Œä¿æŒåŸæ–‡ä¸å˜ã€‚æ¯æ®µæ ‡æ³¨æ¥æºã€‚

æ ¼å¼ï¼š
**æ¥æºï¼šã€Šæ–‡æ¡£åã€‹**
> ç›´æ¥ç²˜è´´åŸæ–‡ï¼Œä¸€å­—ä¸æ”¹

ï¼ˆå¦‚æœ‰å¤šæ®µç›¸å…³å†…å®¹ï¼Œå…¨éƒ¨åˆ—å‡ºï¼‰

### ğŸ“Œ å…³é”®è¦ç‚¹

ç”¨ç®€çŸ­çš„è¦ç‚¹å½¢å¼ï¼Œæç‚¼åŸæ–‡ä¸­çš„æ ¸å¿ƒä¿¡æ¯ï¼ˆä¸æ˜¯æ”¹å†™ï¼Œæ˜¯æç‚¼å…³é”®è¯ï¼‰ã€‚

### âœ… å»ºè®®è¡ŒåŠ¨

åŸºäºåŸæ–‡å†…å®¹ï¼Œç»™å‡º1-3æ¡å¯æ‰§è¡Œçš„å»ºè®®ã€‚

---

**ç¦æ­¢äº‹é¡¹ï¼š**
- ç¦æ­¢æ”¹å†™åŸæ–‡
- ç¦æ­¢ç¼–é€ ä¸å­˜åœ¨çš„å†…å®¹
- ç¦æ­¢æ·»åŠ åŸæ–‡ä¸­æ²¡æœ‰çš„ä¿¡æ¯
- æ‰€æœ‰å†…å®¹å¿…é¡»æ¥è‡ªä¸Šæ–¹çŸ¥è¯†åº“åŸæ–‡`;
}

export async function chat(
  message: string,
  modelType: ModelType = 'deepseek',
  history: ChatMessage[] = []
): Promise<ChatResult> {
  if (!['deepseek', 'kimi'].includes(modelType)) {
    modelType = 'deepseek';
  }

  const documents = getStoredDocuments();
  const totalChunks = getTotalChunksCount();

  console.log(`[Chat] Query: "${message}"`);
  console.log(`[Chat] Documents: ${documents.join(', ') || 'none'}, Total chunks: ${totalChunks}`);

  const relevantChunks = await searchVectorStore(message, 10);
  console.log(`[Chat] Retrieved ${relevantChunks.length} chunks`);

  let context = '';
  const sources: string[] = [];

  if (relevantChunks.length > 0) {
    context = relevantChunks
      .map((chunk, index) => {
        const docName = chunk.metadata.fileName;
        if (!sources.includes(docName)) {
          sources.push(docName);
        }
        return `ã€ç¬¬${index + 1}æ®µã€‘æ¥æºï¼šã€Š${docName}ã€‹
"${chunk.text}"`;
      })
      .join('\n\n---\n\n');
  }

  const hasContext = context.length > 0;
  const systemPrompt = buildSystemPrompt(documents, context, hasContext);

  const messages: ChatMessage[] = [
    { role: 'system', content: systemPrompt },
    ...history.slice(-4),
    { role: 'user', content: message },
  ];

  const modelOrder: ModelType[] = modelType === 'kimi' ? ['kimi', 'deepseek'] : ['deepseek', 'kimi'];
  let lastError: Error | null = null;

  for (const model of modelOrder) {
    try {
      const config = modelConfigs[model];
      if (!config.apiKey) continue;

      console.log(`[Chat] Using: ${config.displayName}`);
      const client = getClient(model);

      const completion = await client.chat.completions.create({
        model: config.model,
        messages: messages.map(m => ({ role: m.role, content: m.content })),
        temperature: 0.2, // Very low for strict adherence
        max_tokens: 3000,
      });

      const response = completion.choices[0]?.message?.content || 'æ— æ³•ç”Ÿæˆå›å¤';
      console.log(`[Chat] Response from ${config.displayName}`);

      return { response, sources, model: config.displayName };
    } catch (error) {
      lastError = error as Error;
      console.error(`[Chat] Error from ${model}:`, error);
    }
  }

  throw lastError || new Error('AIæœåŠ¡å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥');
}

export function getAvailableModels(): { id: ModelType; name: string; available: boolean }[] {
  return Object.entries(modelConfigs).map(([id, config]) => ({
    id: id as ModelType,
    name: config.displayName,
    available: !!config.apiKey,
  }));
}
